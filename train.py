# -*- coding: utf-8 -*-
"""train.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15jZAggt1nH0XAYCnnDBltPQv77OFUF9B
"""

import os
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import models
from torch.utils.data import DataLoader, Dataset
from albumentations import Compose, Resize, Rotate, HorizontalFlip, RandomBrightnessContrast, GaussianBlur, GaussNoise
from albumentations.pytorch import ToTensorV2
import pandas as pd
from PIL import Image
from tqdm import tqdm
import torchvision.transforms as T

# Custom Dataset Class
class PrescriptionDataset(Dataset):
    def __init__(self, csv_file, root_dir, transform=None, normalize=None):
        self.data = pd.read_csv(csv_file)
        self.root_dir = root_dir
        self.transform = transform
        self.normalize = normalize
        self.label_map = {label: idx for idx, label in enumerate(self.data['MEDICINE_NAME'].unique())}

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        img_name = self.data.iloc[idx, 0]
        img_path = os.path.join(self.root_dir, img_name)
        image = Image.open(img_path).convert("RGB")
        if self.transform:
            image = self.transform(image=np.array(image))["image"]
        image = image.float()
        if self.normalize:
            image = self.normalize(image)
        label = self.label_map[self.data.iloc[idx, 1]]
        return image, label

# Paths to directories and CSV files
train_dir = "/content/drive/MyDrive/Training/training_words"
train_csv = "/content/drive/MyDrive/Training/training_labels.csv"
val_dir = "/content/drive/MyDrive/Validation/validation_words"
val_csv = "/content/drive/MyDrive/Validation/validation_labels.csv"

# Data Augmentation for training
train_transform = Compose([
    Resize(224, 224),
    Rotate(limit=20, p=0.5),
    HorizontalFlip(p=0.5),
    RandomBrightnessContrast(p=0.5),
    GaussianBlur(blur_limit=(3,5), p=0.3),
    GaussNoise(var_limit=(10.0, 50.0), p=0.3),
    ToTensorV2(),
])

# Test Transformations
test_transform = Compose([
    Resize(224, 224),
    ToTensorV2(),
])

normalize = T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])

# Dataset instances
train_dataset = PrescriptionDataset(train_csv, train_dir, transform=train_transform, normalize=normalize)
val_dataset = PrescriptionDataset(val_csv, val_dir, transform=test_transform, normalize=normalize)

# Data loaders
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)

# Model setup: EfficientNet with transfer learning
model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1)
model.classifier[1] = nn.Linear(model.classifier[1].in_features, len(train_dataset.label_map))

# Define loss and optimizer
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)

# Training and validation functions
def train_epoch(model, loader, criterion, optimizer):
    model.train()
    total_loss, correct = 0, 0
    for images, labels in tqdm(loader):
        images, labels = images.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        total_loss += loss.item()
        _, preds = torch.max(outputs, 1)
        correct += (preds == labels).sum().item()
    return total_loss / len(loader), correct / len(loader.dataset)

def evaluate(model, loader, criterion):
    model.eval()
    total_loss, correct = 0, 0
    with torch.no_grad():
        for images, labels in loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss = criterion(outputs, labels)
            total_loss += loss.item()
            _, preds = torch.max(outputs, 1)
            correct += (preds == labels).sum().item()
    return total_loss / len(loader), correct / len(loader.dataset)

# Training loop
epochs = 20
best_val_acc = 0
for epoch in range(epochs):
    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer)
    val_loss, val_acc = evaluate(model, val_loader, criterion)

    print(f"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}")

    # Save model with highest validation accuracy
    if val_acc > best_val_acc:
        best_val_acc = val_acc
        torch.save(model.state_dict(), "best_model.pth")